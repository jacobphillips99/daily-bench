# HELM scenarios.

entries: [
  # NarrativeQA
  {description: "narrative_qa:model=text,output_format_instructions=narrative_qa,temperature=0,increase_max_tokens=10000", priority: 1}

  # NaturalQuestions
  {description: "natural_qa:model=text,mode=openbook_longans,output_format_instructions=natural_qa,temperature=0,increase_max_tokens=10000", priority: 1}
  {description: "natural_qa:model=text,mode=closedbook,output_format_instructions=natural_qa,temperature=0,increase_max_tokens=10000", priority: 1}

  # OpenbookQA
  {description: "commonsense:model=text_code,dataset=openbookqa,method=multiple_choice_joint,output_format_instructions=openbookqa,temperature=0,increase_max_tokens=10000", priority: 1}
]
