# daily-bench
DailyBench is a lightweight daily benchmark runner for LLMs. We use DailyBench to ensure that providers are not empirically degrading in quality, quantizing, or otherwise changing their models in a way that is not transparent to end-users. We run DailyBench every 4 hours, log the results, and store them in a git repo. You can see the results at [https://github.com/daily-bench/daily-bench](https://github.com/daily-bench/daily-bench). (todo: make static site)

# Daily Bench Dashboard

A web-based dashboard for visualizing model performance data from the daily-bench benchmarking system.

## Features

- **Time Series Visualization**: Track model performance over time with interactive charts
- **Performance Comparison**: Compare recent runs side-by-side
- **Summary Statistics**: View key metrics and trends at a glance
- **Data Filtering**: Filter by model, scenario, metric, and data split
- **Raw Data View**: Inspect the underlying data with customizable table views
- **Responsive Design**: Works on desktop and mobile devices

## Quick Start

### Local Development

1. **Clone the repository and navigate to the dashboard directory**:
   ```bash
   # If you're in the daily-bench repo root
   cd /path/to/daily-bench
   ```

2. **Start a local web server**:
   
   **Option A: Using Python**:
   ```bash
   python -m http.server 8000
   ```
   
   **Option B: Using Node.js**:
   ```bash
   npx serve .
   ```
   
   **Option C: Using any other static server**:
   ```bash
   # Example with PHP
   php -S localhost:8000
   ```

3. **Open your browser**:
   Navigate to `http://localhost:8000` to view the dashboard.

4. **Load your data**:
   - The dashboard will automatically try to load data from `results/benchmark_summary.csv`
   - If no default file is found, use the "Load CSV File" button to upload your data

### Data Format

The dashboard expects CSV data with the following columns (generated by `extract_results()` in `extractor.py`):

- `model`: Model name (e.g., "gpt-3.5-turbo")
- `scenario_class`: Dataset/scenario name (e.g., "BoolQScenario")
- `metric_name`: Metric name (e.g., "exact_match", "f1_score")
- `split`: Data split (e.g., "test", "validation")
- `run_timestamp`: Timestamp of the run
- `run_date`: Date of the run
- `mean`: Mean metric value
- `count`, `std`, etc.: Additional statistical measures

## GitHub Pages Deployment

### Method 1: Direct Upload

1. **Prepare your files**:
   ```bash
   # Copy the dashboard files to your GitHub repo
   cp index.html style.css script.js /path/to/your-github-repo/
   cp -r results/ /path/to/your-github-repo/  # Include your CSV data
   ```

2. **Commit and push**:
   ```bash
   git add .
   git commit -m "Add daily-bench dashboard"
   git push origin main
   ```

3. **Enable GitHub Pages**:
   - Go to your repository settings
   - Scroll to "Pages" section
   - Select source branch (usually `main`)
   - Your site will be available at `https://yourusername.github.io/repository-name`

### Method 2: Automated Deployment

Create a GitHub Action to automatically update the dashboard when new benchmark data is available:

1. **Create `.github/workflows/deploy-dashboard.yml`**:
   ```yaml
   name: Deploy Dashboard
   
   on:
     push:
       paths:
         - 'results/**'
         - 'index.html'
         - 'style.css'
         - 'script.js'
   
   jobs:
     deploy:
       runs-on: ubuntu-latest
       steps:
         - uses: actions/checkout@v3
         
         - name: Deploy to GitHub Pages
           uses: peaceiris/actions-gh-pages@v3
           with:
             github_token: ${{ secrets.GITHUB_TOKEN }}
             publish_dir: .
             include_assets: true
   ```

## File Structure

```
daily-bench-dashboard/
├── index.html          # Main HTML page
├── style.css           # Styling and layout
├── script.js           # JavaScript functionality
├── README.md           # This file
└── results/
    └── benchmark_summary.csv  # Your benchmark data
```

## Usage

### Viewing Performance Over Time

1. Select a model from the dropdown
2. Choose a scenario/dataset
3. Pick a metric to track
4. Optionally filter by data split
5. View the time series chart showing performance evolution

### Comparing Recent Runs

The "Recent Performance Comparison" chart automatically shows the last 5 runs for the selected filters, making it easy to spot trends and improvements.

### Summary Statistics

Key metrics are displayed in cards showing:
- Latest performance value with trend indicator
- Average performance across all runs
- Minimum and maximum values
- Number of runs and data points
- Time span of the data

### Raw Data Inspection

Use the data table at the bottom to inspect individual data points. You can control how many rows to display and see all the detailed metrics.

## Customization

### Adding New Visualizations

To add new charts or visualizations:

1. Add a new container in `index.html`
2. Create a corresponding update function in `script.js`
3. Call it from `updateVisualizations()`

### Styling Changes

Modify `style.css` to change:
- Color scheme (see CSS variables at the top)
- Layout and spacing
- Chart styling
- Responsive behavior

### Data Processing

The `processCSVData()` function in `script.js` handles data parsing and transformation. Modify it to:
- Add new computed columns
- Change data filtering logic
- Adjust data aggregation

## Integration with Daily Bench

To automatically update the dashboard with new benchmark results:

1. **Modify your benchmark script** to copy results to the dashboard directory:
   ```python
   # In your benchmark automation
   import shutil
   
   # After running extract_results()
   shutil.copy("results/benchmark_summary.csv", "dashboard/results/")
   ```

2. **Set up automated deployment** using GitHub Actions (see deployment section above)

3. **Configure periodic updates** using cron jobs or GitHub Actions scheduled runs

## Troubleshooting

### Data Not Loading

- Check browser console for errors
- Ensure CSV file is properly formatted
- Verify the file path is correct
- Check for CORS issues when serving locally

### Charts Not Displaying

- Ensure Plotly.js is loading correctly
- Check for JavaScript errors in console
- Verify data has the expected column names
- Make sure filters are not excluding all data

### Performance Issues

- Limit the amount of data loaded (filter by date range)
- Reduce the number of data points in charts
- Consider data aggregation for large datasets

## Dependencies

- **Plotly.js**: For interactive charts and visualizations
- **D3.js**: For data processing and manipulation
- **Modern browser**: Supports ES6+ features

No build process or package manager required - just open `index.html` in a web browser!

## Quick Summary

You now have:

1. **`dashboard/`** - A complete static website for visualizing benchmark results
   - Just open `dashboard/index.html` in a browser or use any web server
   - Automatically loads data from `benchmark_summary.csv` 
   - Easy to deploy to GitHub Pages

2. **Simple workflow**:
   ```bash
   # Run benchmarks
   daily-bench run
   
   # Extract results (automatically copies to dashboard)
   daily-bench extract
   
   # View dashboard
   cd dashboard && python serve.py
   # or just open dashboard/index.html
   ```

3. **Easy deployment**: The `dashboard/` folder is ready to deploy to any static hosting service like GitHub Pages.
